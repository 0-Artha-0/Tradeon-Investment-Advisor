name: Scheduled FastAPI Scraper

on:
  schedule:
    - cron: '0 5 * * *'  # Daily at midnight UTC
  workflow_dispatch:      # Manual trigger for first run

jobs:
  run:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Try to download accounts.db
        id: download
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: twscrape-db
          path: .

      - name: Seed accounts.db from secret if missing
        if: steps.download.outcome == 'failure'
        run: |
          echo "${{ secrets.ENCODED_DB }}" | base64 --decode > accounts.db

      - name: Run your app
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        run: python main.py

        - name: Debug file changes
          run: |
            ls -l
            git status
            git diff

      - name: Commit and push updated memory files
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add investment_memory.xlsx today_dashboard_data.json
          git commit -m "Update memory files from scheduled run" || echo "No changes to commit"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload updated accounts.db
        uses: actions/upload-artifact@v4
        with:
          name: twscrape-db
          path: accounts.db
